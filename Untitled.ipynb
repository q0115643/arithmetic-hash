{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing from raw Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_fp = './data/corpora/brown.txt'\n",
    "train_tokens_csv_fp = './data/train_tokens.csv'\n",
    "test_tokens_csv_fp = './data/test_tokens.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm_notebook\n",
    "from util import list_to_string, only_alphabets\n",
    "import csv\n",
    "import sys\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s %(message)s', datefmt='%m-%d %H:%M', stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-15 15:52 Tokenizing Brown Corpus...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f8f77a35c14940a35825d390330db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=51763), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "logging.info('Tokenizing Brown Corpus...')\n",
    "with open(brown_fp, 'r') as brown:\n",
    "    brown = list(brown)\n",
    "    for line in tqdm_notebook(brown, total=len(brown)):\n",
    "        words = word_tokenize(only_alphabets(line))\n",
    "        tokens += words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-15 15:52 Writing Token-Count info on new csv file...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b215033bb574482a1e458f44f3437d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39513), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d31b7ac233484582234be555e46bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=14445), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Writing Token-Count info on new csv file...\")\n",
    "train_tokens, test_tokens = train_test_split(tokens, test_size=0.1)\n",
    "with open(train_tokens_csv_fp, 'w') as csvfile:\n",
    "    fieldnames = [\n",
    "        'token',\n",
    "        'count'\n",
    "    ]\n",
    "    writer = csv.DictWriter(\n",
    "        csvfile,\n",
    "        fieldnames=fieldnames,\n",
    "        quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    output = []\n",
    "    token_counter = sorted(Counter(train_tokens).items(), key=lambda pair: pair[1], reverse=True)\n",
    "    for tok, cnt in tqdm_notebook(token_counter):\n",
    "        output.append({'token': tok,\n",
    "                       'count': cnt})\n",
    "    writer.writerows(output)\n",
    "with open(test_tokens_csv_fp, 'w') as csvfile:\n",
    "    fieldnames = [\n",
    "        'token',\n",
    "        'count'\n",
    "    ]\n",
    "    writer = csv.DictWriter(\n",
    "        csvfile,\n",
    "        fieldnames=fieldnames,\n",
    "        quoting=csv.QUOTE_ALL)\n",
    "    writer.writeheader()\n",
    "    output = []\n",
    "    token_counter = sorted(Counter(test_tokens).items(), key=lambda pair: pair[1], reverse=True)\n",
    "    for tok, cnt in tqdm_notebook(token_counter):\n",
    "        output.append({'token': tok,\n",
    "                       'count': cnt})\n",
    "    writer.writerows(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-15 15:52 PyTorch version: 1.0.0\n",
      "01-15 15:52 GPU Detected: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from util import to_categorical\n",
    "from util import CharDataset\n",
    "import string\n",
    "logging.info(\"PyTorch version: {}\".format(torch.__version__))\n",
    "logging.info(\"GPU Detected: {}\".format(torch.cuda.is_available()))\n",
    "using_GPU = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-15 15:52 int2char\n",
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '<PAD>'}\n",
      "01-15 15:52 char2int\n",
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '<PAD>': 0}\n"
     ]
    }
   ],
   "source": [
    "alphabets = list(string.ascii_lowercase)\n",
    "alphabet_size = len(alphabets) + 1\n",
    "int2char = dict(enumerate(alphabets, start=1))\n",
    "int2char[0] = '<PAD>'\n",
    "char2int = {char: index for index, char in int2char.items()}\n",
    "logging.info('int2char')\n",
    "print(int2char)\n",
    "logging.info('char2int')\n",
    "print(char2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = []\n",
    "with open(train_tokens_csv_fp) as f:\n",
    "    lines = csv.reader(f)\n",
    "    next(lines)\n",
    "    for line in lines:\n",
    "        tok = line[0]\n",
    "        cnt = int(line[1])\n",
    "        for i in range(cnt):\n",
    "            train_tokens.append(tok)\n",
    "train_tokens = [np.array([char2int[char] for char in token]) for token in train_tokens]\n",
    "test_tokens = []\n",
    "with open(test_tokens_csv_fp) as f:\n",
    "    lines = csv.reader(f)\n",
    "    next(lines)\n",
    "    for line in lines:\n",
    "        tok = line[0]\n",
    "        cnt = int(line[1])\n",
    "        for i in range(cnt):\n",
    "            test_tokens.append(tok)\n",
    "test_tokens = [np.array([char2int[char] for char in token]) for token in test_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-15 15:55 One-hot Encoding Train Tokens...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a93c5f1e774491fb468c1d096ea171b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=921177), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "01-15 15:56 One-hot Encoding Test Tokens...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38674991f29c4b84a836ad45a511da4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=102353), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_train_tokens = []\n",
    "logging.info('One-hot Encoding Train Tokens...')\n",
    "for token in tqdm_notebook(train_tokens):\n",
    "    encoded_train_tokens.append(to_categorical(token, alphabet_size))\n",
    "encoded_test_tokens = []\n",
    "logging.info('One-hot Encoding Test Tokens...')\n",
    "for token in tqdm_notebook(test_tokens):\n",
    "    encoded_test_tokens.append(to_categorical(token, alphabet_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens, val_tokens = train_test_split(encoded_train_tokens, test_size=0.05)\n",
    "test_tokens = encoded_test_tokens\n",
    "training_dataset = CharDataset(train_tokens)\n",
    "val_dataset = CharDataset(val_tokens)\n",
    "test_dataset = CharDataset(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=training_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=CharDataset.collate_fn)\n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            collate_fn=CharDataset.collate_fn)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             collate_fn=CharDataset.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import CharLSTM\n",
    "import torch.nn as nn\n",
    "hidden_dim = 64\n",
    "dropout1 = 0.2\n",
    "dropout2 = 0\n",
    "dropout3 = 0.2\n",
    "lr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_model = CharLSTM(alphabet_size=alphabet_size,\n",
    "                     hidden_dim=hidden_dim,\n",
    "                     batch_size=batch_size,\n",
    "                     dropout1=dropout1, dropout2=dropout2, dropout3=dropout3)\n",
    "if using_GPU:\n",
    "    RNN_model = RNN_model.cuda()\n",
    "loss_criterion = nn.NLLLoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(RNN_model.parameters(), lr=lr)\n",
    "#optimizer = torch.optim.SGD(RNN_model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from util import evaluate\n",
    "model_path = './data/checkpoint/rnn.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-15 15:58 ******************************\n",
      "01-15 15:58 Epoch 0. Learning Rate 0.5\n",
      "01-15 15:58 ******************************\n",
      "01-15 15:58 Iteration 400. Training Loss 0.9497.\n",
      "01-15 15:58 Validation Loss 0.8390. Validataion Accuracy 0.75.\n",
      "01-15 15:58 New Best Validation Loss 9999999.0000 -> 0.8390, Saving Model Checkpoint\n",
      "01-15 15:58 Iteration 800. Training Loss 0.7758.\n",
      "01-15 15:58 Validation Loss 0.7937. Validataion Accuracy 0.76.\n",
      "01-15 15:58 New Best Validation Loss 0.8390 -> 0.7937, Saving Model Checkpoint\n",
      "01-15 15:58 Iteration 1200. Training Loss 0.8828.\n",
      "01-15 15:58 Validation Loss 0.7740. Validataion Accuracy 0.76.\n",
      "01-15 15:58 New Best Validation Loss 0.7937 -> 0.7740, Saving Model Checkpoint\n",
      "01-15 15:58 Iteration 1600. Training Loss 0.8465.\n",
      "01-15 15:58 Validation Loss 0.7661. Validataion Accuracy 0.77.\n",
      "01-15 15:58 New Best Validation Loss 0.7740 -> 0.7661, Saving Model Checkpoint\n",
      "01-15 15:59 Iteration 2000. Training Loss 0.7871.\n",
      "01-15 15:59 Validation Loss 0.7614. Validataion Accuracy 0.77.\n",
      "01-15 15:59 New Best Validation Loss 0.7661 -> 0.7614, Saving Model Checkpoint\n",
      "01-15 15:59 Iteration 2400. Training Loss 0.7881.\n",
      "01-15 15:59 Validation Loss 0.7631. Validataion Accuracy 0.77.\n",
      "01-15 15:59 Learning Rate Decay 0.5 -> 0.45\n",
      "01-15 15:59 Iteration 2800. Training Loss 0.8748.\n",
      "01-15 15:59 Validation Loss 0.7562. Validataion Accuracy 0.77.\n",
      "01-15 15:59 New Best Validation Loss 0.7614 -> 0.7562, Saving Model Checkpoint\n",
      "01-15 15:59 Iteration 3200. Training Loss 0.7814.\n",
      "01-15 15:59 Validation Loss 0.7559. Validataion Accuracy 0.77.\n",
      "01-15 15:59 New Best Validation Loss 0.7562 -> 0.7559, Saving Model Checkpoint\n",
      "01-15 15:59 ******************************\n",
      "01-15 15:59 Epoch 1. Learning Rate 0.45\n",
      "01-15 15:59 ******************************\n",
      "01-15 15:59 Iteration 3600. Training Loss 0.9967.\n",
      "01-15 15:59 Validation Loss 0.7596. Validataion Accuracy 0.77.\n",
      "01-15 15:59 Learning Rate Decay 0.45 -> 0.405\n",
      "01-15 15:59 Iteration 4000. Training Loss 0.9344.\n",
      "01-15 15:59 Validation Loss 0.7501. Validataion Accuracy 0.77.\n",
      "01-15 15:59 New Best Validation Loss 0.7559 -> 0.7501, Saving Model Checkpoint\n",
      "01-15 16:00 Iteration 4400. Training Loss 0.7701.\n",
      "01-15 16:00 Validation Loss 0.7543. Validataion Accuracy 0.77.\n",
      "01-15 16:00 Iteration 4800. Training Loss 0.8890.\n",
      "01-15 16:00 Validation Loss 0.7609. Validataion Accuracy 0.76.\n",
      "01-15 16:00 Learning Rate Decay 0.405 -> 0.36450000000000005\n",
      "01-15 16:00 Iteration 5200. Training Loss 0.8966.\n",
      "01-15 16:00 Validation Loss 0.7527. Validataion Accuracy 0.77.\n",
      "01-15 16:00 Learning Rate Decay 0.36450000000000005 -> 0.32805000000000006\n",
      "01-15 16:00 Iteration 5600. Training Loss 0.8501.\n",
      "01-15 16:00 Validation Loss 0.7511. Validataion Accuracy 0.77.\n",
      "01-15 16:00 Learning Rate Decay 0.32805000000000006 -> 0.2952450000000001\n",
      "01-15 16:00 Iteration 6000. Training Loss 0.7914.\n",
      "01-15 16:00 Validation Loss 0.7498. Validataion Accuracy 0.77.\n",
      "01-15 16:00 New Best Validation Loss 0.7501 -> 0.7498, Saving Model Checkpoint\n",
      "01-15 16:01 Iteration 6400. Training Loss 0.6050.\n",
      "01-15 16:01 Validation Loss 0.7546. Validataion Accuracy 0.77.\n",
      "01-15 16:01 Iteration 6800. Training Loss 0.8875.\n",
      "01-15 16:01 Validation Loss 0.7475. Validataion Accuracy 0.77.\n",
      "01-15 16:01 New Best Validation Loss 0.7498 -> 0.7475, Saving Model Checkpoint\n",
      "01-15 16:01 ******************************\n",
      "01-15 16:01 Epoch 2. Learning Rate 0.2952450000000001\n",
      "01-15 16:01 ******************************\n",
      "01-15 16:01 Iteration 7200. Training Loss 0.8208.\n",
      "01-15 16:01 Validation Loss 0.7488. Validataion Accuracy 0.77.\n",
      "01-15 16:01 Learning Rate Decay 0.2952450000000001 -> 0.2657205000000001\n",
      "01-15 16:01 Iteration 7600. Training Loss 0.8199.\n",
      "01-15 16:01 Validation Loss 0.7509. Validataion Accuracy 0.77.\n",
      "01-15 16:01 Learning Rate Decay 0.2657205000000001 -> 0.23914845000000007\n",
      "01-15 16:01 Iteration 8000. Training Loss 0.8933.\n",
      "01-15 16:01 Validation Loss 0.7436. Validataion Accuracy 0.77.\n",
      "01-15 16:01 New Best Validation Loss 0.7475 -> 0.7436, Saving Model Checkpoint\n",
      "01-15 16:02 Iteration 8400. Training Loss 0.8408.\n",
      "01-15 16:02 Validation Loss 0.7398. Validataion Accuracy 0.77.\n",
      "01-15 16:02 New Best Validation Loss 0.7436 -> 0.7398, Saving Model Checkpoint\n",
      "01-15 16:02 Iteration 8800. Training Loss 0.8551.\n",
      "01-15 16:02 Validation Loss 0.7400. Validataion Accuracy 0.77.\n",
      "01-15 16:02 Learning Rate Decay 0.23914845000000007 -> 0.21523360500000008\n",
      "01-15 16:02 Iteration 9200. Training Loss 0.7124.\n",
      "01-15 16:02 Validation Loss 0.7381. Validataion Accuracy 0.78.\n",
      "01-15 16:02 New Best Validation Loss 0.7398 -> 0.7381, Saving Model Checkpoint\n",
      "01-15 16:02 Iteration 9600. Training Loss 0.7248.\n",
      "01-15 16:02 Validation Loss 0.7425. Validataion Accuracy 0.77.\n",
      "01-15 16:02 Learning Rate Decay 0.21523360500000008 -> 0.19371024450000007\n",
      "01-15 16:02 Iteration 10000. Training Loss 0.7781.\n",
      "01-15 16:02 Validation Loss 0.7362. Validataion Accuracy 0.77.\n",
      "01-15 16:02 New Best Validation Loss 0.7381 -> 0.7362, Saving Model Checkpoint\n",
      "01-15 16:02 ******************************\n",
      "01-15 16:02 Epoch 3. Learning Rate 0.19371024450000007\n",
      "01-15 16:02 ******************************\n",
      "01-15 16:03 Iteration 10400. Training Loss 0.8172.\n",
      "01-15 16:03 Validation Loss 0.7396. Validataion Accuracy 0.77.\n",
      "01-15 16:03 Learning Rate Decay 0.19371024450000007 -> 0.17433922005000008\n",
      "01-15 16:03 Iteration 10800. Training Loss 0.7590.\n",
      "01-15 16:03 Validation Loss 0.7354. Validataion Accuracy 0.77.\n",
      "01-15 16:03 New Best Validation Loss 0.7362 -> 0.7354, Saving Model Checkpoint\n",
      "01-15 16:03 Iteration 11200. Training Loss 0.8226.\n",
      "01-15 16:03 Validation Loss 0.7383. Validataion Accuracy 0.77.\n",
      "01-15 16:03 Learning Rate Decay 0.17433922005000008 -> 0.15690529804500009\n",
      "01-15 16:03 Iteration 11600. Training Loss 0.8904.\n",
      "01-15 16:03 Validation Loss 0.7339. Validataion Accuracy 0.78.\n",
      "01-15 16:03 New Best Validation Loss 0.7354 -> 0.7339, Saving Model Checkpoint\n",
      "01-15 16:03 Iteration 12000. Training Loss 0.8900.\n",
      "01-15 16:03 Validation Loss 0.7326. Validataion Accuracy 0.78.\n",
      "01-15 16:03 New Best Validation Loss 0.7339 -> 0.7326, Saving Model Checkpoint\n",
      "01-15 16:04 Iteration 12400. Training Loss 0.8960.\n",
      "01-15 16:04 Validation Loss 0.7324. Validataion Accuracy 0.78.\n",
      "01-15 16:04 New Best Validation Loss 0.7326 -> 0.7324, Saving Model Checkpoint\n",
      "01-15 16:04 Iteration 12800. Training Loss 0.7719.\n",
      "01-15 16:04 Validation Loss 0.7364. Validataion Accuracy 0.77.\n",
      "01-15 16:04 Learning Rate Decay 0.15690529804500009 -> 0.14121476824050008\n",
      "01-15 16:04 Iteration 13200. Training Loss 0.7931.\n",
      "01-15 16:04 Validation Loss 0.7319. Validataion Accuracy 0.77.\n",
      "01-15 16:04 New Best Validation Loss 0.7324 -> 0.7319, Saving Model Checkpoint\n",
      "01-15 16:04 Iteration 13600. Training Loss 0.6369.\n",
      "01-15 16:04 Validation Loss 0.7305. Validataion Accuracy 0.78.\n",
      "01-15 16:04 New Best Validation Loss 0.7319 -> 0.7305, Saving Model Checkpoint\n",
      "01-15 16:04 ******************************\n",
      "01-15 16:04 Epoch 4. Learning Rate 0.14121476824050008\n",
      "01-15 16:04 ******************************\n",
      "01-15 16:04 Iteration 14000. Training Loss 0.7127.\n",
      "01-15 16:04 Validation Loss 0.7315. Validataion Accuracy 0.78.\n",
      "01-15 16:04 Learning Rate Decay 0.14121476824050008 -> 0.12709329141645007\n",
      "01-15 16:05 Iteration 14400. Training Loss 0.7855.\n",
      "01-15 16:05 Validation Loss 0.7341. Validataion Accuracy 0.77.\n",
      "01-15 16:05 Learning Rate Decay 0.12709329141645007 -> 0.11438396227480506\n",
      "01-15 16:05 Iteration 14800. Training Loss 0.6925.\n",
      "01-15 16:05 Validation Loss 0.7311. Validataion Accuracy 0.77.\n",
      "01-15 16:05 Learning Rate Decay 0.11438396227480506 -> 0.10294556604732455\n",
      "01-15 16:05 Iteration 15200. Training Loss 0.8797.\n",
      "01-15 16:05 Validation Loss 0.7279. Validataion Accuracy 0.78.\n",
      "01-15 16:05 New Best Validation Loss 0.7305 -> 0.7279, Saving Model Checkpoint\n",
      "01-15 16:05 Iteration 15600. Training Loss 0.7739.\n",
      "01-15 16:05 Validation Loss 0.7274. Validataion Accuracy 0.78.\n",
      "01-15 16:05 New Best Validation Loss 0.7279 -> 0.7274, Saving Model Checkpoint\n",
      "01-15 16:05 Iteration 16000. Training Loss 0.9264.\n",
      "01-15 16:05 Validation Loss 0.7263. Validataion Accuracy 0.78.\n",
      "01-15 16:05 New Best Validation Loss 0.7274 -> 0.7263, Saving Model Checkpoint\n",
      "01-15 16:05 Iteration 16400. Training Loss 0.8471.\n",
      "01-15 16:05 Validation Loss 0.7261. Validataion Accuracy 0.78.\n",
      "01-15 16:05 New Best Validation Loss 0.7263 -> 0.7261, Saving Model Checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-15 16:06 Iteration 16800. Training Loss 0.8110.\n",
      "01-15 16:06 Validation Loss 0.7273. Validataion Accuracy 0.78.\n",
      "01-15 16:06 Learning Rate Decay 0.10294556604732455 -> 0.0926510094425921\n",
      "01-15 16:06 ******************************\n",
      "01-15 16:06 Epoch 5. Learning Rate 0.0926510094425921\n",
      "01-15 16:06 ******************************\n",
      "01-15 16:06 Iteration 17200. Training Loss 0.8364.\n",
      "01-15 16:06 Validation Loss 0.7253. Validataion Accuracy 0.78.\n",
      "01-15 16:06 New Best Validation Loss 0.7261 -> 0.7253, Saving Model Checkpoint\n",
      "01-15 16:06 Iteration 17600. Training Loss 0.7395.\n",
      "01-15 16:06 Validation Loss 0.7254. Validataion Accuracy 0.78.\n",
      "01-15 16:06 Learning Rate Decay 0.0926510094425921 -> 0.08338590849833288\n",
      "01-15 16:06 Iteration 18000. Training Loss 0.7166.\n",
      "01-15 16:06 Validation Loss 0.7272. Validataion Accuracy 0.78.\n",
      "01-15 16:06 Learning Rate Decay 0.08338590849833288 -> 0.0750473176484996\n",
      "01-15 16:06 Iteration 18400. Training Loss 0.6408.\n",
      "01-15 16:06 Validation Loss 0.7266. Validataion Accuracy 0.78.\n",
      "01-15 16:06 Learning Rate Decay 0.0750473176484996 -> 0.06754258588364964\n",
      "01-15 16:07 Iteration 18800. Training Loss 0.7536.\n",
      "01-15 16:07 Validation Loss 0.7251. Validataion Accuracy 0.78.\n",
      "01-15 16:07 New Best Validation Loss 0.7253 -> 0.7251, Saving Model Checkpoint\n",
      "01-15 16:07 Iteration 19200. Training Loss 0.7656.\n",
      "01-15 16:07 Validation Loss 0.7298. Validataion Accuracy 0.78.\n",
      "01-15 16:07 Learning Rate Decay 0.06754258588364964 -> 0.06078832729528468\n",
      "01-15 16:07 Iteration 19600. Training Loss 0.6875.\n",
      "01-15 16:07 Validation Loss 0.7295. Validataion Accuracy 0.78.\n",
      "01-15 16:07 Learning Rate Decay 0.06078832729528468 -> 0.05470949456575622\n",
      "01-15 16:07 Stop By KeyboardInterrupt...\n"
     ]
    }
   ],
   "source": [
    "num_iter = 0\n",
    "min_val_loss = 9999999\n",
    "min_train_loss = 9999999\n",
    "train_loss_record = []\n",
    "eval_loss_record = []\n",
    "RNN_model.train()\n",
    "try:\n",
    "    for epoch in range(30):\n",
    "        logging.info(\"*\" * 30)\n",
    "        logging.info('Epoch {}. Learning Rate {}'.format(epoch, lr))\n",
    "        logging.info(\"*\" * 30)\n",
    "        for (inputs, targets, lengths) in train_dataloader:\n",
    "            inputs = Variable(inputs) # shape(batch_size, longest_length, alphabet_num) (ex. 128, 13, 28)\n",
    "            lengths = Variable(lengths)\n",
    "            targets = Variable(targets)\n",
    "            if using_GPU:\n",
    "                inputs = inputs.cuda() # [128, maxlen, 26]\n",
    "                lengths = lengths.cuda()\n",
    "                targets = targets.cuda()\n",
    "            output = RNN_model(inputs, lengths) # [batch_size, maxlen, hidden_dim]\n",
    "            batch_loss = loss_criterion(output.view(-1, alphabet_size), targets.view(-1))\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_record.append(batch_loss.item())\n",
    "            num_iter += 1\n",
    "            if num_iter % 400 == 0:\n",
    "                val_loss, accuracy = evaluate(RNN_model, val_dataloader, loss_criterion, alphabet_size, using_GPU)\n",
    "                eval_loss_record.append(val_loss)\n",
    "                logging.info(\"Iteration {}. Training Loss {:.4f}.\".format(num_iter, batch_loss))\n",
    "                logging.info(\"Validation Loss {:.4f}. Validataion Accuracy {:.2f}.\".format(val_loss, accuracy))\n",
    "                if min_val_loss > val_loss:\n",
    "                    logging.info(\"New Best Validation Loss {:.4f} -> {:.4f}, Saving Model Checkpoint\".format(min_val_loss, val_loss))\n",
    "                    min_val_loss = val_loss\n",
    "                    torch.save({'model': RNN_model.state_dict(),\n",
    "                                'optimizer': optimizer.state_dict(),\n",
    "                                'train_loss_record': train_loss_record,\n",
    "                                'eval_loss_record': eval_loss_record\n",
    "                               }, model_path)\n",
    "                elif min_train_loss < batch_loss:\n",
    "                    new_lr = lr * 0.9\n",
    "                    logging.info(\"Learning Rate Decay {} -> {}\".format(lr, new_lr))\n",
    "                    lr = new_lr\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        param_group['lr'] = lr\n",
    "                if min_train_loss > batch_loss:\n",
    "                    min_train_loss = batch_loss\n",
    "except KeyboardInterrupt:\n",
    "    logging.info(\"Stop By KeyboardInterrupt...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-15 16:07 Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "state = torch.load(model_path)\n",
    "eval_loss_record = state['eval_loss_record']\n",
    "train_loss_record = state['train_loss_record']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0098152cc0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-15 16:07 update_title_pos\n",
      "01-15 16:07 update_title_pos\n",
      "01-15 16:07 update_title_pos\n",
      "01-15 16:07 update_title_pos\n",
      "01-15 16:07 update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Validation Loss in Gradient Descent\")\n",
    "plt.plot(eval_loss_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f00982975c0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-15 16:07 update_title_pos\n",
      "01-15 16:07 update_title_pos\n",
      "01-15 16:07 update_title_pos\n",
      "01-15 16:07 update_title_pos\n",
      "01-15 16:07 update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Training Loss in Gradient Descent\")\n",
    "plt.plot(train_loss_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkout Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 0.1142321182574033), ('b', 0.04475687082938458), ('c', 0.04866491456039393), ('d', 0.029906304651549052), ('e', 0.023790216212519418), ('f', 0.04227526306019364), ('g', 0.016970679901908103), ('h', 0.05347180834953543), ('i', 0.06706203042412044), ('j', 0.007376432542280148), ('k', 0.004767813351831407), ('l', 0.024181020585620352), ('m', 0.039451701464539385), ('n', 0.021494240520551426), ('o', 0.07071605131261419), ('p', 0.03974480474436509), ('q', 0.0020419528494523853), ('r', 0.025832169061971805), ('s', 0.0764901859251805), ('t', 0.1595751956464393), ('u', 0.011567809443787677), ('v', 0.006712065108008558), ('w', 0.06012525280157885), ('x', 2.9310327982570125e-05), ('y', 0.008548845661582953), ('z', 0.00021494240520551425)]\n"
     ]
    }
   ],
   "source": [
    "char_probs = []\n",
    "with open(test_tokens_csv_fp) as f:\n",
    "    lines = csv.reader(f)\n",
    "    next(lines)\n",
    "    for line in lines:\n",
    "        tok = line[0]\n",
    "        cnt = int(line[1])\n",
    "        for i in range(cnt):\n",
    "            char_probs.append(tok[0])\n",
    "char_probs = sorted(Counter(char_probs).items(), key=lambda pair: pair[0], reverse=False)\n",
    "total_cnt = 0\n",
    "for (_, cnt) in char_probs:\n",
    "    total_cnt += cnt\n",
    "for idx, (c, cnt) in enumerate(char_probs):\n",
    "    char_probs[idx] = (c, float(cnt)/float(total_cnt))\n",
    "print(char_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 0.12121149), ('b', 0.050893523), ('c', 0.046010073), ('d', 0.021876125), ('e', 0.026788687), ('f', 0.045225702), ('g', 0.015140357), ('h', 0.052354753), ('i', 0.05956704), ('j', 0.0051380666), ('k', 0.005776867), ('l', 0.026021672), ('m', 0.0378599), ('n', 0.023605607), ('o', 0.077236965), ('p', 0.032334596), ('q', 0.0021797873), ('r', 0.02748524), ('s', 0.09068422), ('t', 0.14068814), ('u', 0.012324616), ('v', 0.007626959), ('w', 0.06395412), ('x', 3.7695827e-05), ('y', 0.007600985), ('z', 0.0003767802)]\n"
     ]
    }
   ],
   "source": [
    "RNN_model = CharLSTM(alphabet_size=alphabet_size,\n",
    "                     hidden_dim=hidden_dim,\n",
    "                     batch_size=batch_size,\n",
    "                     dropout1=dropout1, dropout2=dropout2, dropout3=dropout3)\n",
    "if using_GPU:\n",
    "    RNN_model = RNN_model.cuda()\n",
    "state = torch.load(model_path)\n",
    "RNN_model.load_state_dict(state['model'])\n",
    "RNN_model.eval()\n",
    "hidden = RNN_model.init_hidden()\n",
    "start = [torch.Tensor(np.zeros((1, alphabet_size)))]\n",
    "start = torch.stack(start)\n",
    "with torch.no_grad():\n",
    "    start = Variable(start)\n",
    "    if using_GPU:\n",
    "        start = start.cuda()\n",
    "        hidden = (hidden[0].cuda(), hidden[1].cuda())\n",
    "    output, hidden = RNN_model.forward2(start, hidden)\n",
    "predicted_char_probs = []\n",
    "for idx, prob in enumerate(list(output.cpu().numpy()[0][0])):\n",
    "    if idx != 0:\n",
    "        predicted_char_probs.append((int2char[idx], prob))\n",
    "print(predicted_char_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-15 16:08 Comparing Actual Probabilities of the First Character with Predicted Probabilities by LSTM\n",
      "char: a \tactual: 0.1142  \tpredicted: 0.1212 \tdifference: 0.00698\n",
      "char: b \tactual: 0.0448  \tpredicted: 0.0509 \tdifference: 0.00614\n",
      "char: c \tactual: 0.0487  \tpredicted: 0.0460 \tdifference: -0.00265\n",
      "char: d \tactual: 0.0299  \tpredicted: 0.0219 \tdifference: -0.00803\n",
      "char: e \tactual: 0.0238  \tpredicted: 0.0268 \tdifference: 0.00300\n",
      "char: f \tactual: 0.0423  \tpredicted: 0.0452 \tdifference: 0.00295\n",
      "char: g \tactual: 0.0170  \tpredicted: 0.0151 \tdifference: -0.00183\n",
      "char: h \tactual: 0.0535  \tpredicted: 0.0524 \tdifference: -0.00112\n",
      "char: i \tactual: 0.0671  \tpredicted: 0.0596 \tdifference: -0.00749\n",
      "char: j \tactual: 0.0074  \tpredicted: 0.0051 \tdifference: -0.00224\n",
      "char: k \tactual: 0.0048  \tpredicted: 0.0058 \tdifference: 0.00101\n",
      "char: l \tactual: 0.0242  \tpredicted: 0.0260 \tdifference: 0.00184\n",
      "char: m \tactual: 0.0395  \tpredicted: 0.0379 \tdifference: -0.00159\n",
      "char: n \tactual: 0.0215  \tpredicted: 0.0236 \tdifference: 0.00211\n",
      "char: o \tactual: 0.0707  \tpredicted: 0.0772 \tdifference: 0.00652\n",
      "char: p \tactual: 0.0397  \tpredicted: 0.0323 \tdifference: -0.00741\n",
      "char: q \tactual: 0.0020  \tpredicted: 0.0022 \tdifference: 0.00014\n",
      "char: r \tactual: 0.0258  \tpredicted: 0.0275 \tdifference: 0.00165\n",
      "char: s \tactual: 0.0765  \tpredicted: 0.0907 \tdifference: 0.01419\n",
      "char: t \tactual: 0.1596  \tpredicted: 0.1407 \tdifference: -0.01889\n",
      "char: u \tactual: 0.0116  \tpredicted: 0.0123 \tdifference: 0.00076\n",
      "char: v \tactual: 0.0067  \tpredicted: 0.0076 \tdifference: 0.00091\n",
      "char: w \tactual: 0.0601  \tpredicted: 0.0640 \tdifference: 0.00383\n",
      "char: x \tactual: 0.0000  \tpredicted: 0.0000 \tdifference: 0.00001\n",
      "char: y \tactual: 0.0085  \tpredicted: 0.0076 \tdifference: -0.00095\n",
      "char: z \tactual: 0.0002  \tpredicted: 0.0004 \tdifference: 0.00016\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Comparing Actual Probabilities of the First Character with Predicted Probabilities by LSTM\")\n",
    "for actual, predicted in zip(char_probs, predicted_char_probs):\n",
    "    difference = predicted[1] - actual[1]\n",
    "    print('char: {} \\tactual: {:.4f}  \\tpredicted: {:.4f} \\tdifference: {:.5f}'.format(actual[0],\n",
    "                                                                                       actual[1],\n",
    "                                                                                       predicted[1],\n",
    "                                                                                       difference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Markov:\n",
    "    \"\"\"An nth-Order Markov Chain class with some lexical processing elements.\"\"\"\n",
    "    def __init__(self, order):\n",
    "        \"\"\"Initialized with a delimiting character (usually a space) and the order of the Markov chain.\"\"\"\n",
    "        self.states = {}\n",
    "        if order > 0:\n",
    "            self.order = order\n",
    "        else:\n",
    "            raise Exception('Markov Chain order cannot be negative or zero.')\n",
    "        self.states[self.init_chain()] = self.empty_counter()\n",
    "        \n",
    "    def init_chain(self):\n",
    "        \"\"\"Helper function to generate the correct initial chain value.\"\"\"\n",
    "        init = []\n",
    "        for i in range(self.order):\n",
    "            init.append('');\n",
    "        return tuple(init)\n",
    "    \n",
    "    def empty_counter(self):\n",
    "        empty_cnt = {}\n",
    "        alphabets = list(string.ascii_lowercase)\n",
    "        for a in alphabets:\n",
    "            empty_cnt[a] = 0\n",
    "        return empty_cnt\n",
    "\n",
    "    def step(self, a, e):\n",
    "        \"\"\"Helper function that pops the end of tuple 'a' and tags on str 'e'.\"\"\"\n",
    "        d = a[1:] + (e,)\n",
    "        return d\n",
    "    \n",
    "    def learn(self, token_counter):\n",
    "        \"\"\"Adds states to the dictionary; works best with sentences.\"\"\"\n",
    "        for tok, cnt in token_counter:\n",
    "            prev = self.init_chain()\n",
    "            for c in tok:\n",
    "                if prev not in self.states:\n",
    "                    self.states[prev] = self.empty_counter()\n",
    "                curr = self.step(prev, c)\n",
    "                self.states[prev][c] += cnt\n",
    "                prev = curr\n",
    "    \n",
    "    def get_probs(self, prefix):\n",
    "        request = self.init_chain()\n",
    "        if len(prefix) > 0:\n",
    "            for c in prefix:\n",
    "                request = self.step(request, c)\n",
    "        char_counter = self.states[request]\n",
    "        char_probs = []\n",
    "        total_cnt = 0\n",
    "        for tok, cnt in char_counter.items():\n",
    "            total_cnt += cnt\n",
    "        for tok, cnt in char_counter.items():\n",
    "            prob = float(cnt)/float(total_cnt)\n",
    "            char_probs.append(tuple([tok, prob]))\n",
    "        return char_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = list(string.ascii_lowercase)\n",
    "alphabet_size = len(alphabets) + 1\n",
    "int2char = dict(enumerate(alphabets, start=1))\n",
    "int2char[0] = '<PAD>'\n",
    "char2int = {char: index for index, char in int2char.items()}\n",
    "\n",
    "train_token_counter = []\n",
    "with open(train_tokens_csv_fp) as f:\n",
    "    lines = csv.reader(f)\n",
    "    next(lines)\n",
    "    for line in lines:\n",
    "        tok = line[0]\n",
    "        cnt = int(line[1])\n",
    "        train_token_counter.append(tuple([tok, cnt]))\n",
    "mc = Markov(3)\n",
    "mc.learn(train_token_counter)\n",
    "markov_char_probs = mc.get_probs('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-15 16:31 Comparing Actual Probabilities of the First Character with Predicted Probabilities by Markov Chain\n",
      "char: a \tactual: 0.1142  \tpredicted: 0.1135 \tdifference: -0.00071\n",
      "char: b \tactual: 0.0448  \tpredicted: 0.0459 \tdifference: 0.00113\n",
      "char: c \tactual: 0.0487  \tpredicted: 0.0482 \tdifference: -0.00043\n",
      "char: d \tactual: 0.0299  \tpredicted: 0.0307 \tdifference: 0.00080\n",
      "char: e \tactual: 0.0238  \tpredicted: 0.0244 \tdifference: 0.00065\n",
      "char: f \tactual: 0.0423  \tpredicted: 0.0416 \tdifference: -0.00067\n",
      "char: g \tactual: 0.0170  \tpredicted: 0.0171 \tdifference: 0.00016\n",
      "char: h \tactual: 0.0535  \tpredicted: 0.0538 \tdifference: 0.00031\n",
      "char: i \tactual: 0.0671  \tpredicted: 0.0671 \tdifference: 0.00007\n",
      "char: j \tactual: 0.0074  \tpredicted: 0.0071 \tdifference: -0.00024\n",
      "char: k \tactual: 0.0048  \tpredicted: 0.0051 \tdifference: 0.00035\n",
      "char: l \tactual: 0.0242  \tpredicted: 0.0241 \tdifference: -0.00009\n",
      "char: m \tactual: 0.0395  \tpredicted: 0.0398 \tdifference: 0.00031\n",
      "char: n \tactual: 0.0215  \tpredicted: 0.0218 \tdifference: 0.00034\n",
      "char: o \tactual: 0.0707  \tpredicted: 0.0707 \tdifference: -0.00006\n",
      "char: p \tactual: 0.0397  \tpredicted: 0.0390 \tdifference: -0.00073\n",
      "char: q \tactual: 0.0020  \tpredicted: 0.0019 \tdifference: -0.00012\n",
      "char: r \tactual: 0.0258  \tpredicted: 0.0264 \tdifference: 0.00053\n",
      "char: s \tactual: 0.0765  \tpredicted: 0.0747 \tdifference: -0.00182\n",
      "char: t \tactual: 0.1596  \tpredicted: 0.1595 \tdifference: -0.00008\n",
      "char: u \tactual: 0.0116  \tpredicted: 0.0116 \tdifference: 0.00002\n",
      "char: v \tactual: 0.0067  \tpredicted: 0.0067 \tdifference: -0.00002\n",
      "char: w \tactual: 0.0601  \tpredicted: 0.0604 \tdifference: 0.00032\n",
      "char: x \tactual: 0.0000  \tpredicted: 0.0000 \tdifference: 0.00001\n",
      "char: y \tactual: 0.0085  \tpredicted: 0.0085 \tdifference: -0.00003\n",
      "char: z \tactual: 0.0002  \tpredicted: 0.0002 \tdifference: 0.00001\n"
     ]
    }
   ],
   "source": [
    "char_probs = []\n",
    "with open(test_tokens_csv_fp) as f:\n",
    "    lines = csv.reader(f)\n",
    "    next(lines)\n",
    "    for line in lines:\n",
    "        tok = line[0]\n",
    "        cnt = int(line[1])\n",
    "        for i in range(cnt):\n",
    "            char_probs.append(tok[0])\n",
    "char_probs = sorted(Counter(char_probs).items(), key=lambda pair: pair[0], reverse=False)\n",
    "total_cnt = 0\n",
    "for (_, cnt) in char_probs:\n",
    "    total_cnt += cnt\n",
    "for idx, (c, cnt) in enumerate(char_probs):\n",
    "    char_probs[idx] = (c, float(cnt)/float(total_cnt))\n",
    "logging.info(\"Comparing Actual Probabilities of the First Character with Predicted Probabilities by Markov Chain\")\n",
    "for actual, predicted in zip(char_probs, markov_char_probs):\n",
    "    difference = predicted[1] - actual[1]\n",
    "    print('char: {} \\tactual: {:.4f}  \\tpredicted: {:.4f} \\tdifference: {:.5f}'.format(actual[0],\n",
    "                                                                                       actual[1],\n",
    "                                                                                       predicted[1],\n",
    "                                                                                       difference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (other-env)",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
